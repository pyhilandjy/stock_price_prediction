{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import requests as rq\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tqdm\n",
      "Version: 4.65.0\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: https://tqdm.github.io\n",
      "Author: \n",
      "Author-email: \n",
      "License: MPLv2.0, MIT Licences\n",
      "Location: /opt/homebrew/Caskroom/miniconda/base/envs/yeardream/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: finance-datareader, huggingface-hub, nltk, openai, optuna\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Predicted Close Price</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>stock_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>4413.608254</td>\n",
       "      <td>095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>19115.458024</td>\n",
       "      <td>006840</td>\n",
       "      <td>AK홀딩스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>3665.154136</td>\n",
       "      <td>027410</td>\n",
       "      <td>BGF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>148953.601414</td>\n",
       "      <td>282330</td>\n",
       "      <td>BGF리테일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>6988.950019</td>\n",
       "      <td>138930</td>\n",
       "      <td>BNK금융지주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>7473.347520</td>\n",
       "      <td>024060</td>\n",
       "      <td>흥구석유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>6457.745076</td>\n",
       "      <td>010240</td>\n",
       "      <td>흥국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>2275.888796</td>\n",
       "      <td>189980</td>\n",
       "      <td>흥국에프엔비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>8685.170650</td>\n",
       "      <td>037440</td>\n",
       "      <td>희림</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>6438.295630</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2322 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Predicted Close Price stock_code stock_name\n",
       "0    2023-09-21            4413.608254     095570     AJ네트웍스\n",
       "1    2023-09-21           19115.458024     006840      AK홀딩스\n",
       "2    2023-09-21            3665.154136     027410        BGF\n",
       "3    2023-09-21          148953.601414     282330     BGF리테일\n",
       "4    2023-09-21            6988.950019     138930    BNK금융지주\n",
       "...         ...                    ...        ...        ...\n",
       "2317 2023-09-21            7473.347520     024060       흥구석유\n",
       "2318 2023-09-21            6457.745076     010240         흥국\n",
       "2319 2023-09-21            2275.888796     189980     흥국에프엔비\n",
       "2320 2023-09-21            8685.170650     037440         희림\n",
       "2321 2023-09-21            6438.295630     238490         힘스\n",
       "\n",
       "[2322 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_data_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip =  '52.79.207.181'\n",
    "engine = create_engine(f'mysql+pymysql://jun:1234qwer@{ip}:3306/quant')\n",
    "con = pymysql.connect(user='jun',\n",
    "                      passwd='1234qwer',\n",
    "                      host= ip,\n",
    "                      db='quant',\n",
    "                      charset='utf8')\n",
    "mycursor = con.cursor()\n",
    "# read the sql \n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM df\n",
    "\"\"\"\n",
    "\n",
    "# con을 사용하여 데이터를 읽음\n",
    "stock_price = pd.read_sql_query(sql_query, con)\n",
    "\n",
    "\n",
    "unique_stock_codes = stock_price['stock_code'].unique()\n",
    "predicted_data_list = []  # 빈 리스트 생성\n",
    "failed_stock_codes = []\n",
    "\n",
    "\n",
    "for stock_code in unique_stock_codes:\n",
    "    # 특정 stock_code에 해당하는 데이터만 추출\n",
    "    stock_data = stock_price[stock_price['stock_code'] == stock_code]\n",
    "    # 예측한 날짜 범위 생성 \n",
    "    predicted_dates = pd.date_range(start=stock_data['date'].iloc[-1] + pd.Timedelta(days=1), periods=1)\n",
    "\n",
    "    if len(stock_data) >= seq_len:\n",
    "        metadata = stock_data[['stock_code', 'stock_name']].drop_duplicates()\n",
    "        stock_data.drop(['index', 'stock_code', 'stock_name'], axis=1, inplace=True) # delete 'index', 'stock_code', 'stock_name'\n",
    "        try:\n",
    "            # 저장할 폴더 경로\n",
    "            save_folder = './save_weights/'\n",
    "\n",
    "            # 폴더가 존재하지 않으면 생성\n",
    "            if not os.path.exists(save_folder):\n",
    "                os.makedirs(save_folder)\n",
    "\n",
    "            # save original 'open' prices for later\n",
    "            original_open = stock_data['open'].values\n",
    "\n",
    "            # separate dates for future plotting\n",
    "            dates = pd.to_datetime(stock_data['date'])\n",
    "\n",
    "            # variables for training\n",
    "            cols = list(stock_data)[1:6]\n",
    "\n",
    "            # new dataframe with only training data - 5 columns\n",
    "            stock_data = stock_data[cols].astype(float)\n",
    "\n",
    "            # normalize the dataset\n",
    "            scaler = StandardScaler()\n",
    "            scaler = scaler.fit(stock_data)\n",
    "            stock_data_scaled = scaler.transform(stock_data)\n",
    "\n",
    "            # split to train data and test data\n",
    "            n_train = int(0.9*stock_data_scaled.shape[0])\n",
    "            train_data_scaled = stock_data_scaled[0: n_train]\n",
    "            train_dates = dates[0: n_train]\n",
    "\n",
    "            test_data_scaled = stock_data_scaled[n_train:]\n",
    "            test_dates = dates[n_train:]\n",
    "            # print(test_dates.head(5))\n",
    "\n",
    "            # data reformatting for LSTM\n",
    "            pred_days = 1  # prediction period\n",
    "            seq_len = 14   # sequence length = past days for future prediction.\n",
    "            input_dim = 5  # input_dimension = ['open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "            trainX = []\n",
    "            trainY = []\n",
    "            testX = []\n",
    "            testY = []\n",
    "\n",
    "            for i in range(seq_len, n_train-pred_days +1):\n",
    "                trainX.append(train_data_scaled[i - seq_len:i, 0:train_data_scaled.shape[1]])\n",
    "                trainY.append(train_data_scaled[i + pred_days - 1:i + pred_days, 0])\n",
    "\n",
    "            for i in range(seq_len, len(test_data_scaled)-pred_days +1):\n",
    "                testX.append(test_data_scaled[i - seq_len:i, 0:test_data_scaled.shape[1]])\n",
    "                testY.append(test_data_scaled[i + pred_days - 1:i + pred_days, 0])\n",
    "\n",
    "            trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "            testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "            # print(trainX.shape, trainY.shape)\n",
    "            # print(testX.shape, testY.shape)\n",
    "\n",
    "            # LSTM model\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(64, input_shape=(trainX.shape[1], trainX.shape[2]), # (seq length, input dimension)\n",
    "                        return_sequences=True))\n",
    "            model.add(LSTM(32, return_sequences=False))\n",
    "            model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "            model.summary()\n",
    "\n",
    "            # specify your learning rate\n",
    "            learning_rate = 0.01\n",
    "            # create an Adam optimizer with the specified learning rate\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "            # compile your model using the custom optimizer\n",
    "            model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "\n",
    "            # Try to load weights\n",
    "            try:\n",
    "                model.load_weights('./save_weights/lstm_weights.h5')\n",
    "                \n",
    "                print(\"Loaded model weights from disk\")\n",
    "            except:\n",
    "                print(\"No weights found, training model from scratch\")\n",
    "                # Fit the model\n",
    "                history = model.fit(trainX, trainY, epochs=30, batch_size=32,\n",
    "                                validation_split=0.1, verbose=1)\n",
    "                # Save model weights after training\n",
    "                model.save_weights('./save_weights/lstm_weights.h5')\n",
    "\n",
    "                plt.plot(history.history['loss'], label='Training loss')\n",
    "                plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            # prediction\n",
    "            prediction = model.predict(testX)\n",
    "\n",
    "            # generate array filled with means for prediction\n",
    "            mean_values_pred = np.repeat(scaler.mean_[np.newaxis, :], prediction.shape[0], axis=0)\n",
    "            mean_values_pred[:, 0] = np.squeeze(prediction)\n",
    "            y_pred = scaler.inverse_transform(mean_values_pred)[:, 0]\n",
    "\n",
    "            # generate array filled with means for testY\n",
    "            mean_values_testY = np.repeat(scaler.mean_[np.newaxis, :], testY.shape[0], axis=0)\n",
    "            mean_values_testY[:, 0] = np.squeeze(testY)\n",
    "            testY_original = scaler.inverse_transform(mean_values_testY)[:, 0]\n",
    "\n",
    "            # 새로운 테스트 데이터 생성 (2023-09-21일을 포함하여 마지막 14일의 데이터)\n",
    "            new_test_data = stock_data_scaled[-seq_len:].reshape(1, seq_len, input_dim)\n",
    "\n",
    "            # 새로운 테스트 데이터로 예측 수행\n",
    "            new_prediction = model.predict(new_test_data)\n",
    "\n",
    "            # 역변환하여 원래의 주가 단위로 되돌리기\n",
    "            mean_values_pred = np.repeat(scaler.mean_[np.newaxis, :], new_prediction.shape[0], axis=0)\n",
    "            mean_values_pred[:, 0] = np.squeeze(new_prediction)\n",
    "            predicted_close_price = scaler.inverse_transform(mean_values_pred)[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "            # 예측 결과를 데이터 프레임으로 저장\n",
    "            predicted_data = pd.DataFrame({\n",
    "                'Date': predicted_dates,\n",
    "                'Predicted Close Price': predicted_close_price,\n",
    "                'stock_code': metadata['stock_code'].values[0],\n",
    "                'stock_name': metadata['stock_name'].values[0]\n",
    "            })\n",
    "            predicted_data_list.append(predicted_data)  # 리스트에 예측 데이터 추가\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing stock_code {stock_code}: {e}\")\n",
    "            failed_stock_codes.append(stock_code)\n",
    "\n",
    "\n",
    "# 리스트에 있는 데이터를 하나의 DataFrame으로 합치기\n",
    "predicted_data_combined = pd.concat(predicted_data_list, ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeardream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
